[distilBERT_SST2]
# Execution details
checkpoint_dir = ./models/
training_epoch = 3
batch_size = 32
learning_rate = 1e-5
optimizer = torch.optim.Adam

# Architecture
model = distilbert
#100,6,64
random_seed = 100

# Dataset
dataset = SST2
dataset_dir = ./
data_file_type = .tsv
data_file_sep = \t
#0.00,0.20,0.40,0.60
synthetic_noise = 0.00

# AUM
aum_dir = ./AUM/
fake_label = 2
num_classes = 2
threshold_percentile = 0.005
aum_training_epoch = 1

[distilBERT_CoLA]
# Execution details
checkpoint_dir = ./models/
training_epoch = 5
batch_size = 64
learning_rate = 1e-5
optimizer = torch.optim.Adam

# Architecture
model = distilbert
#100,6,64
random_seed = 100

# Dataset
dataset = CoLA
dataset_dir = ./
data_file_type = .tsv
data_file_sep = \t
#0.00,0.20,0.40,0.60
synthetic_noise = 0.00

# AUM
aum_dir = ./AUM/
fake_label = 2
num_classes = 2
threshold_percentile = 0.001
aum_training_epoch = 6